{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9SCgbPd4m6TTigW82ZPUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yjyuwisely/Bigdata-project/blob/main/CSCI946_Final_Naive_Bayes_%26_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CSCI946 Assignment 1 - Task 3: Classification (Modified)\n",
        "# Naive Bayes and Logistic Regression for Category Classification\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "af9DU57KwVOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TASK 3: CLASSIFICATION - PROPER APPROACH\n",
        "# ============================================================================\n",
        "\n",
        "def prepare_classification_data(df):\n",
        "    \"\"\"\n",
        "    Prepare data for classification - predicting product category\n",
        "    This approach aligns with assignment goals of finding best category\n",
        "    \"\"\"\n",
        "    print(\"=== Data Preparation for Classification ===\")\n",
        "\n",
        "    # Select features for classification (numerical features only as per assignment)\n",
        "    feature_cols = ['current_price', 'raw_price', 'discount', 'likes_count']\n",
        "\n",
        "    # Add derived features\n",
        "    df['price_diff'] = df['raw_price'] - df['current_price']\n",
        "    df['log_current_price'] = np.log1p(df['current_price'])\n",
        "    df['log_likes'] = np.log1p(df['likes_count'])\n",
        "\n",
        "    # Final feature set\n",
        "    feature_cols_extended = ['log_current_price', 'discount', 'log_likes', 'price_diff']\n",
        "\n",
        "    # Prepare X (features) and y (target - category)\n",
        "    X = df[feature_cols_extended].copy()\n",
        "    y = df['category'].copy()\n",
        "\n",
        "    print(f\"Features selected: {feature_cols_extended}\")\n",
        "    print(f\"Target variable: category\")\n",
        "    print(f\"Number of samples: {len(X)}\")\n",
        "    print(f\"Number of features: {X.shape[1]}\")\n",
        "    print(f\"Category distribution:\")\n",
        "    print(y.value_counts())\n",
        "\n",
        "    return X, y, feature_cols_extended\n",
        "\n",
        "def perform_naive_bayes_classification(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Perform Naive Bayes Classification\n",
        "    \"\"\"\n",
        "    print(\"\\n=== NAIVE BAYES CLASSIFICATION ===\")\n",
        "\n",
        "    # Initialize and train Gaussian Naive Bayes\n",
        "    nb_classifier = GaussianNB()\n",
        "    nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_nb = nb_classifier.predict(X_test)\n",
        "    y_prob_nb = nb_classifier.predict_proba(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "\n",
        "    print(\"Naive Bayes Results:\")\n",
        "    print(f\"Accuracy: {accuracy_nb:.4f}\")\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm_nb)\n",
        "\n",
        "    return nb_classifier, y_pred_nb, accuracy_nb\n",
        "\n",
        "def perform_logistic_regression_classification(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Perform Logistic Regression Classification with proper preprocessing\n",
        "    \"\"\"\n",
        "    print(\"\\n=== LOGISTIC REGRESSION CLASSIFICATION ===\")\n",
        "\n",
        "    # Create pipeline with scaling (important for Logistic Regression)\n",
        "    lr_pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', LogisticRegression(\n",
        "            max_iter=2000,\n",
        "            solver='lbfgs',\n",
        "            multi_class='multinomial',\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    lr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_lr = lr_pipeline.predict(X_test)\n",
        "    y_prob_lr = lr_pipeline.predict_proba(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "    print(\"Logistic Regression Results:\")\n",
        "    print(f\"Accuracy: {accuracy_lr:.4f}\")\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm_lr)\n",
        "\n",
        "    return lr_pipeline, y_pred_lr, accuracy_lr\n",
        "\n",
        "def compare_classification_results(X, y, nb_model, lr_model, nb_accuracy, lr_accuracy):\n",
        "    \"\"\"\n",
        "    Compare classification results using cross-validation\n",
        "    \"\"\"\n",
        "    print(\"\\n=== MODEL COMPARISON ===\")\n",
        "\n",
        "    # Cross-validation scores\n",
        "    nb_cv_scores = cross_val_score(nb_model, X, y, cv=5, scoring='accuracy')\n",
        "    lr_cv_scores = cross_val_score(lr_model, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "    print(f\"Naive Bayes Cross-Validation Accuracy: {nb_cv_scores.mean():.4f} (+/- {nb_cv_scores.std() * 2:.4f})\")\n",
        "    print(f\"Logistic Regression Cross-Validation Accuracy: {lr_cv_scores.mean():.4f} (+/- {lr_cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "    # Create comparison table\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Algorithm': ['Naive Bayes', 'Logistic Regression'],\n",
        "        'Test Accuracy': [nb_accuracy, lr_accuracy],\n",
        "        'CV Mean Accuracy': [nb_cv_scores.mean(), lr_cv_scores.mean()],\n",
        "        'CV Std Deviation': [nb_cv_scores.std(), lr_cv_scores.std()]\n",
        "    })\n",
        "\n",
        "    print(\"\\nComparison Summary:\")\n",
        "    print(comparison_df.to_string(index=False))\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "def analyze_feature_importance(lr_model, feature_names, categories):\n",
        "    \"\"\"\n",
        "    Analyze feature importance from Logistic Regression coefficients\n",
        "    \"\"\"\n",
        "    print(\"\\n=== FEATURE IMPORTANCE ANALYSIS ===\")\n",
        "\n",
        "    # Get coefficients (for multi-class, we have coefficients for each class)\n",
        "    coefficients = lr_model.named_steps['classifier'].coef_\n",
        "\n",
        "    # Create feature importance DataFrame\n",
        "    feature_importance = pd.DataFrame(\n",
        "        coefficients.T,\n",
        "        index=feature_names,\n",
        "        columns=categories\n",
        "    )\n",
        "\n",
        "    print(\"Logistic Regression Coefficients by Category:\")\n",
        "    print(feature_importance.round(4))\n",
        "\n",
        "    return feature_importance\n",
        "\n",
        "def identify_best_category_and_products(df, nb_model, lr_model, X, y):\n",
        "    \"\"\"\n",
        "    Use classification results to identify best category and top products\n",
        "    This addresses the main assignment objectives\n",
        "    \"\"\"\n",
        "    print(\"\\n=== ASSIGNMENT OBJECTIVES: BEST CATEGORY & TOP PRODUCTS ===\")\n",
        "\n",
        "    # Calculate category performance metrics\n",
        "    category_stats = df.groupby('category').agg({\n",
        "        'likes_count': ['mean', 'std', 'count'],\n",
        "        'discount': 'mean',\n",
        "        'current_price': 'mean',\n",
        "        'price_diff': 'mean'\n",
        "    }).round(2)\n",
        "\n",
        "    category_stats.columns = ['avg_likes', 'std_likes', 'product_count',\n",
        "                             'avg_discount', 'avg_price', 'avg_price_diff']\n",
        "\n",
        "    # Calculate composite category score\n",
        "    category_stats['category_score'] = (\n",
        "        0.5 * (category_stats['avg_likes'] / category_stats['avg_likes'].max()) +\n",
        "        0.3 * (category_stats['avg_discount'] / 100) +\n",
        "        0.2 * (category_stats['avg_price_diff'] / category_stats['avg_price_diff'].max())\n",
        "    )\n",
        "\n",
        "    # Sort by category score\n",
        "    category_ranking = category_stats.sort_values('category_score', ascending=False)\n",
        "\n",
        "    print(\"Category Performance Ranking:\")\n",
        "    print(category_ranking[['avg_likes', 'avg_discount', 'category_score']])\n",
        "\n",
        "    # Identify best category\n",
        "    best_category = category_ranking.index[0]\n",
        "    print(f\"\\nBest Category: {best_category}\")\n",
        "\n",
        "    # Get top 10 products overall based on composite score\n",
        "    df['product_score'] = (\n",
        "        0.6 * (df['likes_count'] / df['likes_count'].max()) +\n",
        "        0.3 * (df['discount'] / 100) +\n",
        "        0.1 * (df['price_diff'] / df['price_diff'].max())\n",
        "    )\n",
        "\n",
        "    top_10_products = df.nlargest(10, 'product_score')[\n",
        "        ['category', 'current_price', 'likes_count', 'discount', 'product_score']\n",
        "    ].round(3)\n",
        "\n",
        "    print(\"\\nTop 10 Products:\")\n",
        "    print(top_10_products.to_string())\n",
        "\n",
        "    return best_category, top_10_products, category_ranking"
      ],
      "metadata": {
        "id": "Jwzjaa1RweHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MAIN EXECUTION FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def run_task3_classification(df):\n",
        "    \"\"\"\n",
        "    Main function to run Task 3 Classification analysis\n",
        "    \"\"\"\n",
        "    print(\"CSCI946 Assignment 1 - Task 3: Classification Analysis\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Prepare data\n",
        "    X, y, feature_names = prepare_classification_data(df)\n",
        "\n",
        "    # Step 2: Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"\\nData split:\")\n",
        "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "    # Step 3: Perform Naive Bayes Classification\n",
        "    nb_model, nb_predictions, nb_accuracy = perform_naive_bayes_classification(\n",
        "        X_train, X_test, y_train, y_test\n",
        "    )\n",
        "\n",
        "    # Step 4: Perform Logistic Regression Classification\n",
        "    lr_model, lr_predictions, lr_accuracy = perform_logistic_regression_classification(\n",
        "        X_train, X_test, y_train, y_test\n",
        "    )\n",
        "\n",
        "    # Step 5: Compare Results\n",
        "    comparison_results = compare_classification_results(\n",
        "        X, y, nb_model, lr_model, nb_accuracy, lr_accuracy\n",
        "    )\n",
        "\n",
        "    # Step 6: Feature Importance Analysis\n",
        "    categories = sorted(y.unique())\n",
        "    feature_importance = analyze_feature_importance(lr_model, feature_names, categories)\n",
        "\n",
        "    # Step 7: Address Assignment Objectives\n",
        "    best_category, top_10_products, category_ranking = identify_best_category_and_products(\n",
        "        df, nb_model, lr_model, X, y\n",
        "    )\n",
        "\n",
        "    # Return results for reporting\n",
        "    results = {\n",
        "        'nb_model': nb_model,\n",
        "        'lr_model': lr_model,\n",
        "        'nb_accuracy': nb_accuracy,\n",
        "        'lr_accuracy': lr_accuracy,\n",
        "        'comparison_df': comparison_results,\n",
        "        'feature_importance': feature_importance,\n",
        "        'best_category': best_category,\n",
        "        'top_10_products': top_10_products,\n",
        "        'category_ranking': category_ranking\n",
        "    }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "HsbOpq6IwmPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdfUTIKQwLkY",
        "outputId": "89898fba-4140-4c5b-e22c-f5fc9ae4954d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSCI946 Assignment 1 - Task 3: Classification Analysis\n",
            "============================================================\n",
            "=== Data Preparation for Classification ===\n",
            "Features selected: ['log_current_price', 'discount', 'log_likes', 'price_diff']\n",
            "Target variable: category\n",
            "Number of samples: 52733\n",
            "Number of features: 4\n",
            "Category distribution:\n",
            "category\n",
            "women      14809\n",
            "house      12791\n",
            "men        10208\n",
            "bags        6268\n",
            "jewelry     4853\n",
            "beauty      3804\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Data split:\n",
            "Training set: 36913 samples\n",
            "Test set: 15820 samples\n",
            "\n",
            "=== NAIVE BAYES CLASSIFICATION ===\n",
            "Naive Bayes Results:\n",
            "Accuracy: 0.4335\n",
            "\n",
            "Detailed Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bags       0.22      0.05      0.08      1880\n",
            "      beauty       0.27      0.01      0.02      1141\n",
            "       house       0.44      0.50      0.47      3837\n",
            "     jewelry       0.00      0.00      0.00      1456\n",
            "         men       0.63      0.29      0.40      3063\n",
            "       women       0.41      0.89      0.56      4443\n",
            "\n",
            "    accuracy                           0.43     15820\n",
            "   macro avg       0.33      0.29      0.25     15820\n",
            "weighted avg       0.39      0.43      0.36     15820\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  88    2  241    0  152 1397]\n",
            " [  26   11  511    0   76  517]\n",
            " [  85   17 1931    0  193 1611]\n",
            " [  30    4  871    0   36  515]\n",
            " [  83    6  487    0  890 1597]\n",
            " [  83    1  354    0   67 3938]]\n",
            "\n",
            "=== LOGISTIC REGRESSION CLASSIFICATION ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Results:\n",
            "Accuracy: 0.4573\n",
            "\n",
            "Detailed Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bags       0.23      0.02      0.04      1880\n",
            "      beauty       0.00      0.00      0.00      1141\n",
            "       house       0.41      0.54      0.47      3837\n",
            "     jewelry       0.34      0.02      0.03      1456\n",
            "         men       0.52      0.46      0.49      3063\n",
            "       women       0.47      0.83      0.60      4443\n",
            "\n",
            "    accuracy                           0.46     15820\n",
            "   macro avg       0.33      0.31      0.27     15820\n",
            "weighted avg       0.39      0.46      0.38     15820\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  43    0  330    0  327 1180]\n",
            " [  33    0  616   10  148  334]\n",
            " [  42    0 2057   11  511 1216]\n",
            " [  21    0  991   25   38  381]\n",
            " [  21    0  565   15 1418 1044]\n",
            " [  24    0  424   13  290 3692]]\n",
            "\n",
            "=== MODEL COMPARISON ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Cross-Validation Accuracy: 0.3987 (+/- 0.1198)\n",
            "Logistic Regression Cross-Validation Accuracy: 0.4434 (+/- 0.0743)\n",
            "\n",
            "Comparison Summary:\n",
            "          Algorithm  Test Accuracy  CV Mean Accuracy  CV Std Deviation\n",
            "        Naive Bayes       0.433502          0.398651          0.059882\n",
            "Logistic Regression       0.457332          0.443366          0.037144\n",
            "\n",
            "=== FEATURE IMPORTANCE ANALYSIS ===\n",
            "Logistic Regression Coefficients by Category:\n",
            "                     bags  beauty   house  jewelry     men   women\n",
            "log_current_price  0.7217 -0.9830 -1.1979  -1.2537  0.4227  2.2902\n",
            "discount           0.4523 -0.6659 -0.8046  -0.4648 -0.5436  2.0266\n",
            "log_likes         -0.0038 -0.0949 -0.0026   0.0912 -0.1090  0.1191\n",
            "price_diff        -0.4018  1.4420  1.4781   1.2802 -0.5509 -3.2477\n",
            "\n",
            "=== ASSIGNMENT OBJECTIVES: BEST CATEGORY & TOP PRODUCTS ===\n",
            "Category Performance Ranking:\n",
            "          avg_likes  avg_discount  category_score\n",
            "category                                         \n",
            "women        238.17         55.16        0.860695\n",
            "bags         201.00         51.84        0.777488\n",
            "men          189.22         45.06        0.676679\n",
            "jewelry      166.15         53.13        0.628984\n",
            "beauty       150.27         50.44        0.628961\n",
            "house        164.48         49.07        0.627330\n",
            "\n",
            "Best Category: women\n",
            "\n",
            "Top 10 Products:\n",
            "      category  current_price  likes_count  discount  product_score\n",
            "48216    women          19.99        21403        65          0.796\n",
            "48191    women          27.99        17684        53          0.655\n",
            "41673    women          29.99        17414        51          0.642\n",
            "48864    women          25.99        10965        85          0.565\n",
            "37934    women          13.99        14252        48          0.544\n",
            "44311    women          15.35        11165        65          0.509\n",
            "52115    women          38.84        12482        51          0.504\n",
            "41176    women          12.99        12786        46          0.497\n",
            "44416    women          29.99        11498        51          0.476\n",
            "27721      men          20.99        11521        46          0.461\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# USAGE EXAMPLE\n",
        "# ============================================================================\n",
        "\n",
        "#Load your preprocessed data (assuming you have df from previous tasks)\n",
        "df = pd.read_csv('cleaned_combined_dataset.csv')  # Your preprocessed data\n",
        "\n",
        "#Run the classification analysis\n",
        "results = run_task3_classification(df)\n",
        "\n",
        "#Example of how to save results for your report\n",
        "results['comparison_df'].to_csv('classification_comparison.csv', index=False)\n",
        "results['top_10_products'].to_csv('top_10_products.csv', index=False)\n",
        "results['category_ranking'].to_csv('category_ranking.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CSCI946 Assignment 1 - Task 3: Classification Analysis\n",
        "# ============================================================\n",
        "# === Data Preparation for Classification ===\n",
        "# Features selected: ['log_current_price', 'discount', 'log_likes', 'price_diff']\n",
        "# Target variable: category\n",
        "# Number of samples: 52733\n",
        "# Number of features: 4\n",
        "# Category distribution:\n",
        "# category\n",
        "# women      14809\n",
        "# house      12791\n",
        "# men        10208\n",
        "# bags        6268\n",
        "# jewelry     4853\n",
        "# beauty      3804\n",
        "# Name: count, dtype: int64\n",
        "\n",
        "# Data split:\n",
        "# Training set: 36913 samples\n",
        "# Test set: 15820 samples\n",
        "\n",
        "# === NAIVE BAYES CLASSIFICATION ===\n",
        "# Naive Bayes Results:\n",
        "# Accuracy: 0.4335\n",
        "\n",
        "# Detailed Classification Report:\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#         bags       0.22      0.05      0.08      1880\n",
        "#       beauty       0.27      0.01      0.02      1141\n",
        "#        house       0.44      0.50      0.47      3837\n",
        "#      jewelry       0.00      0.00      0.00      1456\n",
        "#          men       0.63      0.29      0.40      3063\n",
        "#        women       0.41      0.89      0.56      4443\n",
        "\n",
        "#     accuracy                           0.43     15820\n",
        "#    macro avg       0.33      0.29      0.25     15820\n",
        "# weighted avg       0.39      0.43      0.36     15820\n",
        "\n",
        "\n",
        "# Confusion Matrix:\n",
        "# [[  88    2  241    0  152 1397]\n",
        "#  [  26   11  511    0   76  517]\n",
        "#  [  85   17 1931    0  193 1611]\n",
        "#  [  30    4  871    0   36  515]\n",
        "#  [  83    6  487    0  890 1597]\n",
        "#  [  83    1  354    0   67 3938]]\n",
        "\n",
        "# === LOGISTIC REGRESSION CLASSIFICATION ===\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# Logistic Regression Results:\n",
        "# Accuracy: 0.4573\n",
        "\n",
        "# Detailed Classification Report:\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#         bags       0.23      0.02      0.04      1880\n",
        "#       beauty       0.00      0.00      0.00      1141\n",
        "#        house       0.41      0.54      0.47      3837\n",
        "#      jewelry       0.34      0.02      0.03      1456\n",
        "#          men       0.52      0.46      0.49      3063\n",
        "#        women       0.47      0.83      0.60      4443\n",
        "\n",
        "#     accuracy                           0.46     15820\n",
        "#    macro avg       0.33      0.31      0.27     15820\n",
        "# weighted avg       0.39      0.46      0.38     15820\n",
        "\n",
        "\n",
        "# Confusion Matrix:\n",
        "# [[  43    0  330    0  327 1180]\n",
        "#  [  33    0  616   10  148  334]\n",
        "#  [  42    0 2057   11  511 1216]\n",
        "#  [  21    0  991   25   38  381]\n",
        "#  [  21    0  565   15 1418 1044]\n",
        "#  [  24    0  424   13  290 3692]]\n",
        "\n",
        "# === MODEL COMPARISON ===\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# Naive Bayes Cross-Validation Accuracy: 0.3987 (+/- 0.1198)\n",
        "# Logistic Regression Cross-Validation Accuracy: 0.4434 (+/- 0.0743)\n",
        "\n",
        "# Comparison Summary:\n",
        "#           Algorithm  Test Accuracy  CV Mean Accuracy  CV Std Deviation\n",
        "#         Naive Bayes       0.433502          0.398651          0.059882\n",
        "# Logistic Regression       0.457332          0.443366          0.037144\n",
        "\n",
        "# === FEATURE IMPORTANCE ANALYSIS ===\n",
        "# Logistic Regression Coefficients by Category:\n",
        "#                      bags  beauty   house  jewelry     men   women\n",
        "# log_current_price  0.7217 -0.9830 -1.1979  -1.2537  0.4227  2.2902\n",
        "# discount           0.4523 -0.6659 -0.8046  -0.4648 -0.5436  2.0266\n",
        "# log_likes         -0.0038 -0.0949 -0.0026   0.0912 -0.1090  0.1191\n",
        "# price_diff        -0.4018  1.4420  1.4781   1.2802 -0.5509 -3.2477\n",
        "\n",
        "# === ASSIGNMENT OBJECTIVES: BEST CATEGORY & TOP PRODUCTS ===\n",
        "# Category Performance Ranking:\n",
        "#           avg_likes  avg_discount  category_score\n",
        "# category\n",
        "# women        238.17         55.16        0.860695\n",
        "# bags         201.00         51.84        0.777488\n",
        "# men          189.22         45.06        0.676679\n",
        "# jewelry      166.15         53.13        0.628984\n",
        "# beauty       150.27         50.44        0.628961\n",
        "# house        164.48         49.07        0.627330\n",
        "\n",
        "# Best Category: women\n",
        "\n",
        "# Top 10 Products:\n",
        "#       category  current_price  likes_count  discount  product_score\n",
        "# 48216    women          19.99        21403        65          0.796\n",
        "# 48191    women          27.99        17684        53          0.655\n",
        "# 41673    women          29.99        17414        51          0.642\n",
        "# 48864    women          25.99        10965        85          0.565\n",
        "# 37934    women          13.99        14252        48          0.544\n",
        "# 44311    women          15.35        11165        65          0.509\n",
        "# 52115    women          38.84        12482        51          0.504\n",
        "# 41176    women          12.99        12786        46          0.497\n",
        "# 44416    women          29.99        11498        51          0.476\n",
        "# 27721      men          20.99        11521        46          0.461"
      ],
      "metadata": {
        "id": "1GA-Lf9OeJGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your preprocessed data\n",
        "df = pd.read_csv('cleaned_combined_dataset.csv')\n",
        "\n",
        "# Run the complete Task 3 analysis\n",
        "results = run_task3_classification(df)\n",
        "\n",
        "# Access specific results for your report\n",
        "print(\"Best Category:\", results['best_category'])\n",
        "print(\"Top 10 Products:\")\n",
        "print(results['top_10_products'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qyC7nJlw1po",
        "outputId": "1db7e2c0-8388-4885-b52a-53d3272adc27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSCI946 Assignment 1 - Task 3: Classification Analysis\n",
            "============================================================\n",
            "=== Data Preparation for Classification ===\n",
            "Features selected: ['log_current_price', 'discount', 'log_likes', 'price_diff']\n",
            "Target variable: category\n",
            "Number of samples: 52733\n",
            "Number of features: 4\n",
            "Category distribution:\n",
            "category\n",
            "women      14809\n",
            "house      12791\n",
            "men        10208\n",
            "bags        6268\n",
            "jewelry     4853\n",
            "beauty      3804\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Data split:\n",
            "Training set: 36913 samples\n",
            "Test set: 15820 samples\n",
            "\n",
            "=== NAIVE BAYES CLASSIFICATION ===\n",
            "Naive Bayes Results:\n",
            "Accuracy: 0.4335\n",
            "\n",
            "Detailed Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bags       0.22      0.05      0.08      1880\n",
            "      beauty       0.27      0.01      0.02      1141\n",
            "       house       0.44      0.50      0.47      3837\n",
            "     jewelry       0.00      0.00      0.00      1456\n",
            "         men       0.63      0.29      0.40      3063\n",
            "       women       0.41      0.89      0.56      4443\n",
            "\n",
            "    accuracy                           0.43     15820\n",
            "   macro avg       0.33      0.29      0.25     15820\n",
            "weighted avg       0.39      0.43      0.36     15820\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  88    2  241    0  152 1397]\n",
            " [  26   11  511    0   76  517]\n",
            " [  85   17 1931    0  193 1611]\n",
            " [  30    4  871    0   36  515]\n",
            " [  83    6  487    0  890 1597]\n",
            " [  83    1  354    0   67 3938]]\n",
            "\n",
            "=== LOGISTIC REGRESSION CLASSIFICATION ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Results:\n",
            "Accuracy: 0.4573\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bags       0.23      0.02      0.04      1880\n",
            "      beauty       0.00      0.00      0.00      1141\n",
            "       house       0.41      0.54      0.47      3837\n",
            "     jewelry       0.34      0.02      0.03      1456\n",
            "         men       0.52      0.46      0.49      3063\n",
            "       women       0.47      0.83      0.60      4443\n",
            "\n",
            "    accuracy                           0.46     15820\n",
            "   macro avg       0.33      0.31      0.27     15820\n",
            "weighted avg       0.39      0.46      0.38     15820\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  43    0  330    0  327 1180]\n",
            " [  33    0  616   10  148  334]\n",
            " [  42    0 2057   11  511 1216]\n",
            " [  21    0  991   25   38  381]\n",
            " [  21    0  565   15 1418 1044]\n",
            " [  24    0  424   13  290 3692]]\n",
            "\n",
            "=== MODEL COMPARISON ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Cross-Validation Accuracy: 0.3987 (+/- 0.1198)\n",
            "Logistic Regression Cross-Validation Accuracy: 0.4434 (+/- 0.0743)\n",
            "\n",
            "Comparison Summary:\n",
            "          Algorithm  Test Accuracy  CV Mean Accuracy  CV Std Deviation\n",
            "        Naive Bayes       0.433502          0.398651          0.059882\n",
            "Logistic Regression       0.457332          0.443366          0.037144\n",
            "\n",
            "=== FEATURE IMPORTANCE ANALYSIS ===\n",
            "Logistic Regression Coefficients by Category:\n",
            "                     bags  beauty   house  jewelry     men   women\n",
            "log_current_price  0.7217 -0.9830 -1.1979  -1.2537  0.4227  2.2902\n",
            "discount           0.4523 -0.6659 -0.8046  -0.4648 -0.5436  2.0266\n",
            "log_likes         -0.0038 -0.0949 -0.0026   0.0912 -0.1090  0.1191\n",
            "price_diff        -0.4018  1.4420  1.4781   1.2802 -0.5509 -3.2477\n",
            "\n",
            "=== ASSIGNMENT OBJECTIVES: BEST CATEGORY & TOP PRODUCTS ===\n",
            "Category Performance Ranking:\n",
            "          avg_likes  avg_discount  category_score\n",
            "category                                         \n",
            "women        238.17         55.16        0.860695\n",
            "bags         201.00         51.84        0.777488\n",
            "men          189.22         45.06        0.676679\n",
            "jewelry      166.15         53.13        0.628984\n",
            "beauty       150.27         50.44        0.628961\n",
            "house        164.48         49.07        0.627330\n",
            "\n",
            "Best Category: women\n",
            "\n",
            "Top 10 Products:\n",
            "      category  current_price  likes_count  discount  product_score\n",
            "48216    women          19.99        21403        65          0.796\n",
            "48191    women          27.99        17684        53          0.655\n",
            "41673    women          29.99        17414        51          0.642\n",
            "48864    women          25.99        10965        85          0.565\n",
            "37934    women          13.99        14252        48          0.544\n",
            "44311    women          15.35        11165        65          0.509\n",
            "52115    women          38.84        12482        51          0.504\n",
            "41176    women          12.99        12786        46          0.497\n",
            "44416    women          29.99        11498        51          0.476\n",
            "27721      men          20.99        11521        46          0.461\n",
            "Best Category: women\n",
            "Top 10 Products:\n",
            "      category  current_price  likes_count  discount  product_score\n",
            "48216    women          19.99        21403        65          0.796\n",
            "48191    women          27.99        17684        53          0.655\n",
            "41673    women          29.99        17414        51          0.642\n",
            "48864    women          25.99        10965        85          0.565\n",
            "37934    women          13.99        14252        48          0.544\n",
            "44311    women          15.35        11165        65          0.509\n",
            "52115    women          38.84        12482        51          0.504\n",
            "41176    women          12.99        12786        46          0.497\n",
            "44416    women          29.99        11498        51          0.476\n",
            "27721      men          20.99        11521        46          0.461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CSCI946 Assignment 1 - Task 3: Classification Analysis\n",
        "# ============================================================\n",
        "# === Data Preparation for Classification ===\n",
        "# Features selected: ['log_current_price', 'discount', 'log_likes', 'price_diff']\n",
        "# Target variable: category\n",
        "# Number of samples: 52733\n",
        "# Number of features: 4\n",
        "# Category distribution:\n",
        "# category\n",
        "# women      14809\n",
        "# house      12791\n",
        "# men        10208\n",
        "# bags        6268\n",
        "# jewelry     4853\n",
        "# beauty      3804\n",
        "# Name: count, dtype: int64\n",
        "\n",
        "# Data split:\n",
        "# Training set: 36913 samples\n",
        "# Test set: 15820 samples\n",
        "\n",
        "# === NAIVE BAYES CLASSIFICATION ===\n",
        "# Naive Bayes Results:\n",
        "# Accuracy: 0.4335\n",
        "\n",
        "# Detailed Classification Report:\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#         bags       0.22      0.05      0.08      1880\n",
        "#       beauty       0.27      0.01      0.02      1141\n",
        "#        house       0.44      0.50      0.47      3837\n",
        "#      jewelry       0.00      0.00      0.00      1456\n",
        "#          men       0.63      0.29      0.40      3063\n",
        "#        women       0.41      0.89      0.56      4443\n",
        "\n",
        "#     accuracy                           0.43     15820\n",
        "#    macro avg       0.33      0.29      0.25     15820\n",
        "# weighted avg       0.39      0.43      0.36     15820\n",
        "\n",
        "\n",
        "# Confusion Matrix:\n",
        "# [[  88    2  241    0  152 1397]\n",
        "#  [  26   11  511    0   76  517]\n",
        "#  [  85   17 1931    0  193 1611]\n",
        "#  [  30    4  871    0   36  515]\n",
        "#  [  83    6  487    0  890 1597]\n",
        "#  [  83    1  354    0   67 3938]]\n",
        "\n",
        "# === LOGISTIC REGRESSION CLASSIFICATION ===\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# Logistic Regression Results:\n",
        "# Accuracy: 0.4573\n",
        "\n",
        "# Detailed Classification Report:\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#         bags       0.23      0.02      0.04      1880\n",
        "#       beauty       0.00      0.00      0.00      1141\n",
        "#        house       0.41      0.54      0.47      3837\n",
        "#      jewelry       0.34      0.02      0.03      1456\n",
        "#          men       0.52      0.46      0.49      3063\n",
        "#        women       0.47      0.83      0.60      4443\n",
        "\n",
        "#     accuracy                           0.46     15820\n",
        "#    macro avg       0.33      0.31      0.27     15820\n",
        "# weighted avg       0.39      0.46      0.38     15820\n",
        "\n",
        "\n",
        "# Confusion Matrix:\n",
        "# [[  43    0  330    0  327 1180]\n",
        "#  [  33    0  616   10  148  334]\n",
        "#  [  42    0 2057   11  511 1216]\n",
        "#  [  21    0  991   25   38  381]\n",
        "#  [  21    0  565   15 1418 1044]\n",
        "#  [  24    0  424   13  290 3692]]\n",
        "\n",
        "# === MODEL COMPARISON ===\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "#   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# /usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
        "#   warnings.warn(\n",
        "# Naive Bayes Cross-Validation Accuracy: 0.3987 (+/- 0.1198)\n",
        "# Logistic Regression Cross-Validation Accuracy: 0.4434 (+/- 0.0743)\n",
        "\n",
        "# Comparison Summary:\n",
        "#           Algorithm  Test Accuracy  CV Mean Accuracy  CV Std Deviation\n",
        "#         Naive Bayes       0.433502          0.398651          0.059882\n",
        "# Logistic Regression       0.457332          0.443366          0.037144\n",
        "\n",
        "# === FEATURE IMPORTANCE ANALYSIS ===\n",
        "# Logistic Regression Coefficients by Category:\n",
        "#                      bags  beauty   house  jewelry     men   women\n",
        "# log_current_price  0.7217 -0.9830 -1.1979  -1.2537  0.4227  2.2902\n",
        "# discount           0.4523 -0.6659 -0.8046  -0.4648 -0.5436  2.0266\n",
        "# log_likes         -0.0038 -0.0949 -0.0026   0.0912 -0.1090  0.1191\n",
        "# price_diff        -0.4018  1.4420  1.4781   1.2802 -0.5509 -3.2477\n",
        "\n",
        "# === ASSIGNMENT OBJECTIVES: BEST CATEGORY & TOP PRODUCTS ===\n",
        "# Category Performance Ranking:\n",
        "#           avg_likes  avg_discount  category_score\n",
        "# category\n",
        "# women        238.17         55.16        0.860695\n",
        "# bags         201.00         51.84        0.777488\n",
        "# men          189.22         45.06        0.676679\n",
        "# jewelry      166.15         53.13        0.628984\n",
        "# beauty       150.27         50.44        0.628961\n",
        "# house        164.48         49.07        0.627330\n",
        "\n",
        "# Best Category: women\n",
        "\n",
        "# Top 10 Products:\n",
        "#       category  current_price  likes_count  discount  product_score\n",
        "# 48216    women          19.99        21403        65          0.796\n",
        "# 48191    women          27.99        17684        53          0.655\n",
        "# 41673    women          29.99        17414        51          0.642\n",
        "# 48864    women          25.99        10965        85          0.565\n",
        "# 37934    women          13.99        14252        48          0.544\n",
        "# 44311    women          15.35        11165        65          0.509\n",
        "# 52115    women          38.84        12482        51          0.504\n",
        "# 41176    women          12.99        12786        46          0.497\n",
        "# 44416    women          29.99        11498        51          0.476\n",
        "# 27721      men          20.99        11521        46          0.461\n",
        "# Best Category: women\n",
        "# Top 10 Products:\n",
        "#       category  current_price  likes_count  discount  product_score\n",
        "# 48216    women          19.99        21403        65          0.796\n",
        "# 48191    women          27.99        17684        53          0.655\n",
        "# 41673    women          29.99        17414        51          0.642\n",
        "# 48864    women          25.99        10965        85          0.565\n",
        "# 37934    women          13.99        14252        48          0.544\n",
        "# 44311    women          15.35        11165        65          0.509\n",
        "# 52115    women          38.84        12482        51          0.504\n",
        "# 41176    women          12.99        12786        46          0.497\n",
        "# 44416    women          29.99        11498        51          0.476\n",
        "# 27721      men          20.99        11521        46          0.461"
      ],
      "metadata": {
        "id": "qBHmUjGQeNeq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
